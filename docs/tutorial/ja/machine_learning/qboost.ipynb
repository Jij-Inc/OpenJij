{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アニーリングを用いたアンサンブル学習（QBoost)\n",
    "\n",
    "[QBoost](https://arxiv.org/abs/0811.0416)は量子アニーリングを用いたアンサンブル学習の一つです。\n",
    "アンサンブル学習は弱い予測器を多数用意し、その予測器の各予測結果を組み合わせることで、最終的に精度の良い予測結果を得る手法です。\n",
    "\n",
    "## 概要と原理\n",
    "\n",
    "このQBoostは、入力信号$\\bm{x}$がどのような性質を持っているのかを精度良く識別することを目標としたアルゴリズムです。ここでは2つの値$\\pm 1$のどちらを入力信号に割り当てるべきかという問題を考えましょう。例として、$\\bm{x}$が画像データを表しており、その画像に写っているものが犬か猫かを識別するといったタスクを想像すると良いでしょう。アンサンブル学習では、複数の予測器を利用することで、より良い予測精度を達成すること(ブースティング)を目指します。ここでは、あまり性能の良くない予測器(弱い予測器)をたくさん用意します。性能が良くないという意味は、入力に対して正しい出力をしないことが多いことを意味します。これらの予測器の出力を$c_i (\\bm{x}) \\in \\{ -1, 1\\} \\ (i=0, 1, \\dots, N-1)$とします。いくつかの弱い予測器の出力の和を取ることで、より良い予測ができるというのが基本的な考え方です。これを数式で表すと\n",
    "\n",
    "$$\n",
    "C(\\bm{x}) \n",
    "= \\mathrm{sgn} \\left( \\sum_{i=0}^{N-1} w_i c_i (\\bm{x}) \\right) \\tag{1}\n",
    "$$\n",
    "\n",
    "となります。ここで$w_i \\in \\{0, 1\\}$で、$i$番目の予測器を使うか使わないかを表します。どの予測器を用いると、できるだけ少ない数の弱い予測器でより良い性能が得られるかを明らかにしましょう。  \n",
    "このために、教師あり学習を用いて最適な$\\{w_i\\}$の組を求めることにします。教師データを$(\\bm{x}^{(d)}, y^{(d)}) \\ (d= 0, 1, \\dots, D-1)$を多数用意します($D \\gg 1$)。それらをできるだけ忠実に再現するように$\\{w_i\\}$を調整します。  \n",
    "この方針をより具体的に表すと、次のハミルトニアンを$\\{w_i\\}$について最小化することを目指せば良いとわかります。\n",
    "\n",
    "$$\n",
    "H(\\bm{w}) \n",
    "= \\sum_{d=0}^{D-1} \\left( \\frac{1}{N} \\sum_{i=0}^{N-1} w_i c_i (\\bm{x}^{(d)}) - y^{(d)}\\right)^2 + \\lambda \\sum_{i=0}^{N-1} w_i \\tag{2}\n",
    "$$ \n",
    "\n",
    "このハミルトニアンの最小化を通して、教師データ$y^{(d)}$との差ができるだけ小さくなるようにします。式(1)の右辺をそのまま使うと、符号関数があるために$w_i$の2次形式にならず、イジング模型に帰着することができません。そのため、符号関数の引数$\\sum_i w_i c_i$の$1/N$倍と教師データ$y^{(d)}$との差の2乗を最小化する問題にしています。$1/N$の係数は、$\\sum_i w_i c_i(\\bm{x})$の最大値が$N$であるために$y^{(d)}= \\pm 1$との差が大きくなりすぎないのように調整するためのものです。$\\lambda (>0)$がかかった項は、あまり多くの$w_i$を1にせず、比較的少数の弱い予測器で効率良く構成するための項(正則化項)を表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JijModelingによるモデル構築\n",
    "\n",
    "### 変数の定義\n",
    "\n",
    "式(2)で用いられている変数を、以下のようにして定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jijmodeling as jm\n",
    "\n",
    "# define variables\n",
    "c = jm.Placeholder(\"c\", ndim=2)\n",
    "y = jm.Placeholder(\"y\", ndim=2)\n",
    "lamb = jm.Placeholder(\"lamb\", latex=\"\\lambda\")\n",
    "N = c.len_at(0, latex=\"N\")\n",
    "D = c.len_at(1, latex=\"D\")\n",
    "w = jm.BinaryVar(\"w\", shape=(N, ))\n",
    "i = jm.Element(\"i\", belong_to=(0, N))\n",
    "d = jm.Element(\"d\", belong_to=(0, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c = jm.Placeholder('c', ndim=2)`で式(2)の$c$を定義しています。\n",
    "そのリストの要素数から、弱い予測器の数$N$と教師データ数$D$をそれぞれ`N, D`として定義しています。\n",
    "それらを用いて、最適化に用いるバイナリ変数`w`と教師データのバイナリ値`y`を定義しています。\n",
    "式(2)の$\\lambda$を`lamb`として定義し、最後に式(2)で用いられている添字を`i, d`のように表しています。\n",
    "\n",
    "### 目的関数の実装\n",
    "\n",
    "式(2)を実装しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "problem = jm.Problem(\"QBoost\")\n",
    "# set objective function 1: minimize the sum of differences\n",
    "problem += jm.sum(i, w[i]*c[i, d]) / N\n",
    "# # set objective function 2: minimize the number of weak classifier\n",
    "# problem += lamb * w[:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{array}{cccc}\\text{Problem:} & \\text{QBoost} & & \\\\& & \\min \\quad \\displaystyle \\sum_{i = 0}^{N - 1} \\sum_{d = 0}^{D - 1} w_{i} \\cdot c_{i, d} \\cdot N^{(-1)} & \\\\\\text{{where}} & & & \\\\& w & 1\\text{-dim binary variable}\\\\\\end{array}$$"
      ],
      "text/plain": [
       "<jijmodeling.Problem at 0x1a29e90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e4ef42922154d6c53cb4e5074b09fe7c3d2526e8e95a3a7b0551dc780a36e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
